{"pages":[],"posts":[{"title":"test","text":"","link":"/2022/09/02/test/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/09/02/hello-world/"},{"title":"test1","text":"","link":"/2022/09/02/test1/"},{"title":"tvm","text":"this is a placeholder for tvm下面测试以下图片捏","link":"/2022/09/04/tvm/"},{"title":"类型萃取","text":"所谓的类型萃取，就算说在某些函数模板中，它需要知道传进来的变量，它的类型到底是啥，用于返回值这类的，但c++是不允许说推导出返回值类型的，例如以下代码是不可能通过编译的template&lt;typename T&gt; (*T) func(T t){ ... }为了解决这种问题，对于我们自定义的类，可以利用typedef去声明，如下 1234567891011template&lt;typename T&gt;struct MyIter{ typedef T value_type; T * ptr; MyIter(T* p):ptr(p){} T&amp; operator*() { return *ptr; }};template&lt;typename T&gt;typename T::value_type func(T t){ std::cout &lt;&lt; *t &lt;&lt; std::endl;} 这样做当传入类型是MyIter&lt;int&gt;的时候，首先MyIter的T会实例化为int,func这个函数模板的T会被实例化为MyIter，那么其返回类型也就是int了，这里的typename是告诉编译器，后面的T::value_type 是一个类型（像int，double这种),不加就可能会被当作是成员变量造成歧义。那当我们传入的是原生指针呢，上面的自定义对象我们可以直接获取它的成员变量的所指对象，但int * 这种就无法通过T::value_type,因为它根本就没有，所以这个时候就可以利用模板偏特化+trait的技巧了，如下 123456789101112131415161718192021template\\&lt;typename T\\&gt;struct MyIter{ typedef T value_type; T * ptr; MyIter(T* p):ptr(p){} T&amp; operator*() { return *ptr; }};template\\&lt;typename T\\&gt;struct iterator_traits{ typedef T::value_type value_type;};template\\&lt;typename T\\&gt;struct iterator_traits\\&lt;T*\\&gt;{ typedef T value_type;};template&lt;typename T&gt;typename iterator_traits&lt;T&gt;::value_type func(T t){ std::cout &lt;&lt; *t &lt;&lt; std::endl; 那么当func传进来的是int *的时候，会调用特例化的第2个模板，那么value_type就是int啦，这样做iterator所指类型不管是什么情况都能知道了，","link":"/2022/09/04/%E7%B1%BB%E5%9E%8B%E8%90%83%E5%8F%96/"},{"title":"内存模型1.md","text":"c++的内存模型挺复杂的，因为现代cpu架构的原因，例如cache等，一些操作我们无法得知他具体什么时候会对其他线程可见，例如说thread A写了一个全局变量，但它很有可能是写到自己的私有cache导致说它的这个写对其他thread不可见，那么c++对于这些就提出了一个叫内存模型的玩意。首先是顺序一致性模型，它规定有2点：1.内存访问执行的顺序与程序指定的顺序相同2.所有核心的内存访问实际执行顺序都和程序指定顺序相同有1个例子就可以说明这个，一个群聊里，每个人的发言记录的顺序是固定的，不可能说先看到晚发出去的信息，而他所看到的所有人的发言记录，与其他的每个人都一样，都是遵循着某种交叉着的顺序，而且大家观察到的顺序都是一样的，而c++默认就是使用这种内存模型，即memory_order_seq_cst,以下面这段代码为例 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;#include &lt;iostream&gt;std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x(){ x.store(true,std::memory_order_seq_cst); // 1}void write_y(){ y.store(true,std::memory_order_seq_cst); // 2}void read_x_then_y(){ while(!x.load(std::memory_order_seq_cst)); if(y.load(std::memory_order_seq_cst)) // 3 ++z; //std::cout &lt;&lt; z &lt;&lt; std::endl;}void read_y_then_x(){ while(!y.load(std::memory_order_seq_cst)); if(x.load(std::memory_order_seq_cst)) // 4 ++z; //std::cout &lt;&lt; z &lt;&lt; std::endl;}int main(){ x=false; y=false; z=0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load()!=0); // 5 std::cout &lt;&lt; z &lt;&lt; std::endl;} 这里assert永远不会报错，且下一步输出的z有可能是1，有可能是2，下面分别分析：如果第1个load是true，但第2个load是false，也就算说它观察到了x的store是先于y的store，或者说在它跳出while的时候，肯定是看到了x的store操作，但y的load还是false，说明它没观察到y的store操作，所以它观察到的所x的store先于y的store，那么对thread d而言，它也必须以这种顺序观察到2个store，所以说thread d的第1个load如果是true了，说明它观察到了y的store，所以它必然已经观察到了x的store，所以它下一步的load必然为true，反过来也同理，这个时候的z就是1了而z=2的情况为还不是很明白，假如说a的第一个load到了某个时间点，观察到了x的store，它退出了while，然后它第2个load，观察到了y是true，但这就没办法确定x和y的store的观察顺序了，如果x的store先于y，那么对d而言，它的2个load必然为ture，z=2，如果y的store是先于x的，那么thread d就可能第2个load是false了，此时z=1（这里好像就是第1种情况了？，这里的解释不一定正确） 接下来是acq-rel模型，它解除了对全局一致性的约束，只单纯地利用memory_order_acquire和memory_order_release,前者如果某个load使用则在load之前的指令都不能跨过该语句被重排到后面，后者则是某个store使用则其后语句不能被重排跨到前面我们经常利用他们去实现同步操作，但是这里要注意，它无法保证全局一致，也就是说，每个thread观测到的顺序是可能不一样的，如下例子： 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x(){ x.store(true,std::memory_order_release);}void write_y(){ y.store(true,std::memory_order_release);}void read_x_then_y(){ while(!x.load(std::memory_order_acquire)); if(y.load(std::memory_order_acquire)) // 1 ++z;}void read_y_then_x(){ while(!y.load(std::memory_order_acquire)); if(x.load(std::memory_order_acquire)) // 2 ++z;}int main(){ x=false; y=false; z=0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load()!=0); // 3} 对于不同thread的对同1个原子变量，acq-rel的语义只能做到——如果在load的时候观察到了store，那么必然就能保证我们需要的同步，如果在load的时候还没观察到store的话就做不到了，如下代码 1234567891011121314151617181920212223242526272829303132#include &lt;thread&gt;#include &lt;atomic&gt;#include &lt;cassert&gt;#include &lt;string&gt;#include &lt;iostream&gt;#include &lt;chrono&gt;std::atomic&lt;std::string*&gt; ptr ;int data; void producer(){ std::this_thread::sleep_for(std::chrono::milliseconds(1000)); std::string* p = new std::string(&quot;Hello&quot;); data = 42; ptr.store(p, std::memory_order_release);} void consumer(){ std::string* p2 = nullptr; //std::this_thread::sleep_for(std::chrono::milliseconds(1000)); p2 = ptr.load(std::memory_order_acquire); assert(*p2 == &quot;Hello&quot;); // never fires assert(data == 42);} int main(){ std::thread t1(producer); std::thread t2(consumer); t1.join(); t2.join();} 这段代码大多数时候是报错的，因为thread 1 sleep了一段时间，所以在第2个thread中，在它load的时候，第1个thread的store因为sleep的原因未执行，导致了它无法做到同步，所以下面的assert必然报错，但如果修改p2，改成while(!p2=ptr.load(std::memory_order_acquire)),就能实现同步了，因为它会一直在while中循环，直到某1次循环中，它观察到了线程1的store操作，那么这2者的同步语义就能建立起来了——线程1的store之前的语句必然先于store，线程2的load之后的语句必然非先于load，而它跳出循环的时候store必然是已经被观测到了，所以这种同步就建立起来了回头看上一段代码，这段代码可能报错的原因就在于，acq-rel语义没有规定全局一致，那么就可能出现thread c观测到x的store先于y的store，而d则反过来，此时他们就都加不了z，或者说我们可以这么理解——全局一致下，c看到了x是true，y只load1次看到是false，说明x的store对d来说也必然先于y的store，而d一直卡在while那里，直到它观测到y是true；但没有全局一致的要求时，以下情况就可能发生——对thread c，它卡在while一段时间退去后，此时它肯定观测到了x的sotre，而它只对y进行了1次load，是false，说明它观测到x的store先于y，但对d而言，没有全局一致的约束，c的观测顺序对它没意义了，它完全可以一直卡在while，直到它观测到y的store，然后在对x进行1次load，发现x的store还没被观察到，对d而言，它是先观测到y后才是x，那么这种矛盾的原因在于，x和y的store它可能是写入内存，而c和d在load的时候，不一定去内存找，它可能直接在自己的cache中找，不一致就来了那么怎么修改这段代码呢，很简单，只要保证x和y他们的被观测到的顺序是一样的就可以了，上述由于是分开被2个线程写的原因如下 123456789101112131415161718192021222324252627#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x_then_y(){ x.store(true,std::memory_order_relaxed); // 1 y.store(true,std::memory_order_release); // 2}void read_y_then_x(){ while(!y.load(std::memory_order_acquire)); // 3 自旋，等待y被设置为true if(x.load(std::memory_order_relaxed)) // 4 ++z;}int main(){ x=false; y=false; z=0; std::thread a(write_x_then_y); std::thread b(read_y_then_x); a.join(); b.join(); assert(z.load()!=0); // 5} 这里就不用解释了，但如果说y的load不是while，而是只读1次，那这种同步性就没有了，因为它完全有可能在load之前没有观察到store，加上while，不断的load，直到某1次，发现y被store为true了，这次的load就和store有了先后顺序了，那么就可以保证同步了","link":"/2022/09/05/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B1/"},{"title":"模板偏特化","text":"","link":"/2022/09/04/%E6%A8%A1%E6%9D%BF%E5%81%8F%E7%89%B9%E5%8C%96-1/"},{"title":"模板偏特化","text":"模板偏特化，就","link":"/2022/09/04/%E6%A8%A1%E6%9D%BF%E5%81%8F%E7%89%B9%E5%8C%96/"},{"title":"shared_ptr线程安全","text":"shared_ptr众所周知的智能指针，其允许多个指针指向同一内存对象，且在引用计数为0的时候自动析构被管理的对象，但是，在多线程的环境下，他的操作不是线程安全的，原因在于，其管理对象的方式是通过指针去管理，而其底层的引用计数本身也是一个指针，指向一个真正的计数对象，当我们执行如下代码的时候 12shared_ptr&lt;A&gt; a1 (new A));shared_ptr&lt;A&gt; a2 = a1; a2在构造的时候，是分为2步的，第1步是让a2管理的A对象指向a1管理的对象，第2步是让a2的引用计数也指向a1的引用计数对象，然后再把count+1那么这种非原子的操作方式就可能带来race condition了，如下代码 1234567891011121314151617181920212223#include &lt;memory&gt;#include &lt;iostream&gt;#include &lt;thread&gt;std::shared_ptr&lt;int&gt; p1 (new int(5));void func1(){ std::shared_ptr&lt;int&gt; p2; p2 = p1; std::cout &lt;&lt; *p2 &lt;&lt; std::endl;}void func2(){ std::shared_ptr&lt;int&gt; p3; p1 = p3;}int main(){ std::thread t1(func1); std::thread t2(func2); t1.join(); t2.join();} 当线程1执行p2 = p1的时候，首先他会把p1管理对象的指针赋值给p2，但这个时候，线程2来了，他的p1 = p3的赋值操作，导致p1原来管理的int(5)变成了1个没人指向的对象，所以其对应的引用计数也为0，且这个原来的对象就被析构了，此时p1所指的引用计数对象，他的count是2，再下一步，来到线程1，p2 = p1指令继续赋值，把p1的新的引用计数对象赋给了p2，那么这个引用计数对象的count就是3了，但此时p2所指的是那个已经被析构了的int(5),这个时候我们再解引用p2，就会报错了，如图：中间的那个偶尔的段错误吐核就是啦所以这里要记住：shared_ptr的实现机制，最核心的就是使用2个指针，指向1个被管理对象和1个与之关联的引用计数对象，在赋值的时候是分2步的非原子操作，所以这个时候一定要加锁使其原子化","link":"/2022/09/05/shared-ptr%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"},{"title":"局部静态对象","text":"c++11规定，在一个函数内的局部静态变量(local static),它的初始化是必须线程安全的，也就是说，它的初始化过程是加锁的，其他线程在其初始化过程中是被阻塞的，否则就可能说1个线程在初始化过程中在还没赋值之前，另1个线程也开始初始化，最后就造成了重复构造，具体如下代码 123456789101112131415161718192021222324252627282930#include &lt;thread&gt;#include &lt;iostream&gt;#include &lt;mutex&gt;class A {public:A(){ std::cout &lt;&lt; &quot;constructing&quot; &lt;&lt; std::endl; }};A&amp; getA(){ static A a; return a;}std::mutex lock;void func(){ A a = getA(); std::unique_lock&lt;std::mutex&gt; mylock (lock); std::cout &lt;&lt; &amp;a &lt;&lt; std::endl;}int main(){ std::thread thread_list[10]; for (int i = 0; i &lt; 10; i++){ thread_list[i] = std::thread(func); } for (int i = 0; i &lt; 10; i++){ thread_list[i].join(); }} 可以看到，这个对象只被正确地构造了1次，其他线程都引用同一个对象这种方式是c++实现单例模式的最佳手段，因为它就是这么简单","link":"/2022/09/05/%E5%B1%80%E9%83%A8%E9%9D%99%E6%80%81%E5%AF%B9%E8%B1%A1/"}],"tags":[{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"c+2","slug":"c-2","link":"/tags/c-2/"},{"name":"tvm","slug":"tvm","link":"/tags/tvm/"}],"categories":[]}