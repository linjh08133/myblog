{"pages":[],"posts":[{"title":"test","text":"","link":"/2022/09/02/test/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/09/02/hello-world/"},{"title":"test1","text":"","link":"/2022/09/02/test1/"},{"title":"tvm","text":"this is a placeholder for tvm下面测试以下图片捏","link":"/2022/09/04/tvm/"},{"title":"类型萃取","text":"所谓的类型萃取，就算说在某些函数模板中，它需要知道传进来的变量，它的类型到底是啥，用于返回值这类的，但c++是不允许说推导出返回值类型的，例如以下代码是不可能通过编译的template&lt;typename T&gt; (*T) func(T t){ ... }为了解决这种问题，对于我们自定义的类，可以利用typedef去声明，如下 1234567891011template&lt;typename T&gt;struct MyIter{ typedef T value_type; T * ptr; MyIter(T* p):ptr(p){} T&amp; operator*() { return *ptr; }};template&lt;typename T&gt;typename T::value_type func(T t){ std::cout &lt;&lt; *t &lt;&lt; std::endl;} 这样做当传入类型是MyIter&lt;int&gt;的时候，首先MyIter的T会实例化为int,func这个函数模板的T会被实例化为MyIter，那么其返回类型也就是int了，这里的typename是告诉编译器，后面的T::value_type 是一个类型（像int，double这种),不加就可能会被当作是成员变量造成歧义。那当我们传入的是原生指针呢，上面的自定义对象我们可以直接获取它的成员变量的所指对象，但int * 这种就无法通过T::value_type,因为它根本就没有，所以这个时候就可以利用模板偏特化+trait的技巧了，如下 123456789101112131415161718192021template\\&lt;typename T\\&gt;struct MyIter{ typedef T value_type; T * ptr; MyIter(T* p):ptr(p){} T&amp; operator*() { return *ptr; }};template\\&lt;typename T\\&gt;struct iterator_traits{ typedef T::value_type value_type;};template\\&lt;typename T\\&gt;struct iterator_traits\\&lt;T*\\&gt;{ typedef T value_type;};template&lt;typename T&gt;typename iterator_traits&lt;T&gt;::value_type func(T t){ std::cout &lt;&lt; *t &lt;&lt; std::endl; 那么当func传进来的是int *的时候，会调用特例化的第2个模板，那么value_type就是int啦，这样做iterator所指类型不管是什么情况都能知道了，","link":"/2022/09/04/%E7%B1%BB%E5%9E%8B%E8%90%83%E5%8F%96/"},{"title":"内存模型1.md","text":"c++的内存模型挺复杂的，因为现代cpu架构的原因，例如cache等，一些操作我们无法得知他具体什么时候会对其他线程可见，例如说thread A写了一个全局变量，但它很有可能是写到自己的私有cache导致说它的这个写对其他thread不可见，那么c++对于这些就提出了一个叫内存模型的玩意。首先是顺序一致性模型，它规定有2点：1.内存访问执行的顺序与程序指定的顺序相同2.所有核心的内存访问实际执行顺序都和程序指定顺序相同有1个例子就可以说明这个，一个群聊里，每个人的发言记录的顺序是固定的，不可能说先看到晚发出去的信息，而他所看到的所有人的发言记录，与其他的每个人都一样，都是遵循着某种交叉着的顺序，而且大家观察到的顺序都是一样的，而c++默认就是使用这种内存模型，即memory_order_seq_cst,以下面这段代码为例 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;#include &lt;iostream&gt;std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x(){ x.store(true,std::memory_order_seq_cst); // 1}void write_y(){ y.store(true,std::memory_order_seq_cst); // 2}void read_x_then_y(){ while(!x.load(std::memory_order_seq_cst)); if(y.load(std::memory_order_seq_cst)) // 3 ++z; //std::cout &lt;&lt; z &lt;&lt; std::endl;}void read_y_then_x(){ while(!y.load(std::memory_order_seq_cst)); if(x.load(std::memory_order_seq_cst)) // 4 ++z; //std::cout &lt;&lt; z &lt;&lt; std::endl;}int main(){ x=false; y=false; z=0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load()!=0); // 5 std::cout &lt;&lt; z &lt;&lt; std::endl;} 这里assert永远不会报错，且下一步输出的z有可能是1，有可能是2，下面分别分析：如果第1个load是true，但第2个load是false，也就算说它观察到了x的store是先于y的store，或者说在它跳出while的时候，肯定是看到了x的store操作，但y的load还是false，说明它没观察到y的store操作，所以它观察到的所x的store先于y的store，那么对thread d而言，它也必须以这种顺序观察到2个store，所以说thread d的第1个load如果是true了，说明它观察到了y的store，所以它必然已经观察到了x的store，所以它下一步的load必然为true，反过来也同理，这个时候的z就是1了而z=2的情况为还不是很明白，假如说a的第一个load到了某个时间点，观察到了x的store，它退出了while，然后它第2个load，观察到了y是true，但这就没办法确定x和y的store的观察顺序了，如果x的store先于y，那么对d而言，它的2个load必然为ture，z=2，如果y的store是先于x的，那么thread d就可能第2个load是false了，此时z=1（这里好像就是第1种情况了？，这里的解释不一定正确） 接下来是acq-rel模型，它解除了对全局一致性的约束，只单纯地利用memory_order_acquire和memory_order_release,前者如果某个load使用则在load之前的指令都不能跨过该语句被重排到后面，后者则是某个store使用则其后语句不能被重排跨到前面我们经常利用他们去实现同步操作，但是这里要注意，它无法保证全局一致，也就是说，每个thread观测到的顺序是可能不一样的，如下例子： 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x(){ x.store(true,std::memory_order_release);}void write_y(){ y.store(true,std::memory_order_release);}void read_x_then_y(){ while(!x.load(std::memory_order_acquire)); if(y.load(std::memory_order_acquire)) // 1 ++z;}void read_y_then_x(){ while(!y.load(std::memory_order_acquire)); if(x.load(std::memory_order_acquire)) // 2 ++z;}int main(){ x=false; y=false; z=0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load()!=0); // 3} 对于不同thread的对同1个原子变量，acq-rel的语义只能做到——如果在load的时候观察到了store，那么必然就能保证我们需要的同步，如果在load的时候还没观察到store的话就做不到了，如下代码 1234567891011121314151617181920212223242526272829303132#include &lt;thread&gt;#include &lt;atomic&gt;#include &lt;cassert&gt;#include &lt;string&gt;#include &lt;iostream&gt;#include &lt;chrono&gt;std::atomic&lt;std::string*&gt; ptr ;int data; void producer(){ std::this_thread::sleep_for(std::chrono::milliseconds(1000)); std::string* p = new std::string(&quot;Hello&quot;); data = 42; ptr.store(p, std::memory_order_release);} void consumer(){ std::string* p2 = nullptr; //std::this_thread::sleep_for(std::chrono::milliseconds(1000)); p2 = ptr.load(std::memory_order_acquire); assert(*p2 == &quot;Hello&quot;); // never fires assert(data == 42);} int main(){ std::thread t1(producer); std::thread t2(consumer); t1.join(); t2.join();} 这段代码大多数时候是报错的，因为thread 1 sleep了一段时间，所以在第2个thread中，在它load的时候，第1个thread的store因为sleep的原因未执行，导致了它无法做到同步，所以下面的assert必然报错，但如果修改p2，改成while(!p2=ptr.load(std::memory_order_acquire)),就能实现同步了，因为它会一直在while中循环，直到某1次循环中，它观察到了线程1的store操作，那么这2者的同步语义就能建立起来了——线程1的store之前的语句必然先于store，线程2的load之后的语句必然非先于load，而它跳出循环的时候store必然是已经被观测到了，所以这种同步就建立起来了回头看上一段代码，这段代码可能报错的原因就在于，acq-rel语义没有规定全局一致，那么就可能出现thread c观测到x的store先于y的store，而d则反过来，此时他们就都加不了z，或者说我们可以这么理解——全局一致下，c看到了x是true，y只load1次看到是false，说明x的store对d来说也必然先于y的store，而d一直卡在while那里，直到它观测到y是true；但没有全局一致的要求时，以下情况就可能发生——对thread c，它卡在while一段时间退去后，此时它肯定观测到了x的sotre，而它只对y进行了1次load，是false，说明它观测到x的store先于y，但对d而言，没有全局一致的约束，c的观测顺序对它没意义了，它完全可以一直卡在while，直到它观测到y的store，然后在对x进行1次load，发现x的store还没被观察到，对d而言，它是先观测到y后才是x，那么这种矛盾的原因在于，x和y的store它可能是写入内存，而c和d在load的时候，不一定去内存找，它可能直接在自己的cache中找，不一致就来了那么怎么修改这段代码呢，很简单，只要保证x和y他们的被观测到的顺序是一样的就可以了，上述由于是分开被2个线程写的原因如下 123456789101112131415161718192021222324252627#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x_then_y(){ x.store(true,std::memory_order_relaxed); // 1 y.store(true,std::memory_order_release); // 2}void read_y_then_x(){ while(!y.load(std::memory_order_acquire)); // 3 自旋，等待y被设置为true if(x.load(std::memory_order_relaxed)) // 4 ++z;}int main(){ x=false; y=false; z=0; std::thread a(write_x_then_y); std::thread b(read_y_then_x); a.join(); b.join(); assert(z.load()!=0); // 5} 这里就不用解释了，但如果说y的load不是while，而是只读1次，那这种同步性就没有了，因为它完全有可能在load之前没有观察到store，加上while，不断的load，直到某1次，发现y被store为true了，这次的load就和store有了先后顺序了，那么就可以保证同步了","link":"/2022/09/05/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B1/"},{"title":"模板偏特化","text":"","link":"/2022/09/04/%E6%A8%A1%E6%9D%BF%E5%81%8F%E7%89%B9%E5%8C%96-1/"},{"title":"模板偏特化","text":"模板偏特化，就","link":"/2022/09/04/%E6%A8%A1%E6%9D%BF%E5%81%8F%E7%89%B9%E5%8C%96/"},{"title":"shared_ptr线程安全","text":"shared_ptr众所周知的智能指针，其允许多个指针指向同一内存对象，且在引用计数为0的时候自动析构被管理的对象，但是，在多线程的环境下，他的操作不是线程安全的，原因在于，其管理对象的方式是通过指针去管理，而其底层的引用计数本身也是一个指针，指向一个真正的计数对象，当我们执行如下代码的时候 12shared_ptr&lt;A&gt; a1 (new A));shared_ptr&lt;A&gt; a2 = a1; a2在构造的时候，是分为2步的，第1步是让a2管理的A对象指向a1管理的对象，第2步是让a2的引用计数也指向a1的引用计数对象，然后再把count+1那么这种非原子的操作方式就可能带来race condition了，如下代码 1234567891011121314151617181920212223#include &lt;memory&gt;#include &lt;iostream&gt;#include &lt;thread&gt;std::shared_ptr&lt;int&gt; p1 (new int(5));void func1(){ std::shared_ptr&lt;int&gt; p2; p2 = p1; std::cout &lt;&lt; *p2 &lt;&lt; std::endl;}void func2(){ std::shared_ptr&lt;int&gt; p3; p1 = p3;}int main(){ std::thread t1(func1); std::thread t2(func2); t1.join(); t2.join();} 当线程1执行p2 = p1的时候，首先他会把p1管理对象的指针赋值给p2，但这个时候，线程2来了，他的p1 = p3的赋值操作，导致p1原来管理的int(5)变成了1个没人指向的对象，所以其对应的引用计数也为0，且这个原来的对象就被析构了，此时p1所指的引用计数对象，他的count是2，再下一步，来到线程1，p2 = p1指令继续赋值，把p1的新的引用计数对象赋给了p2，那么这个引用计数对象的count就是3了，但此时p2所指的是那个已经被析构了的int(5),这个时候我们再解引用p2，就会报错了，如图：中间的那个偶尔的段错误吐核就是啦所以这里要记住：shared_ptr的实现机制，最核心的就是使用2个指针，指向1个被管理对象和1个与之关联的引用计数对象，在赋值的时候是分2步的非原子操作，所以这个时候一定要加锁使其原子化","link":"/2022/09/05/shared-ptr%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"},{"title":"局部静态对象","text":"c++11规定，在一个函数内的局部静态变量(local static),它的初始化是必须线程安全的，也就是说，它的初始化过程是加锁的，其他线程在其初始化过程中是被阻塞的，否则就可能说1个线程在初始化过程中在还没赋值之前，另1个线程也开始初始化，最后就造成了重复构造，具体如下代码 123456789101112131415161718192021222324252627282930#include &lt;thread&gt;#include &lt;iostream&gt;#include &lt;mutex&gt;class A {public:A(){ std::cout &lt;&lt; &quot;constructing&quot; &lt;&lt; std::endl; }};A&amp; getA(){ static A a; return a;}std::mutex lock;void func(){ A a = getA(); std::unique_lock&lt;std::mutex&gt; mylock (lock); std::cout &lt;&lt; &amp;a &lt;&lt; std::endl;}int main(){ std::thread thread_list[10]; for (int i = 0; i &lt; 10; i++){ thread_list[i] = std::thread(func); } for (int i = 0; i &lt; 10; i++){ thread_list[i].join(); }} 可以看到，这个对象只被正确地构造了1次，其他线程都引用同一个对象这种方式是c++实现单例模式的最佳手段，因为它就是这么简单","link":"/2022/09/05/%E5%B1%80%E9%83%A8%E9%9D%99%E6%80%81%E5%AF%B9%E8%B1%A1/"},{"title":"一个可扩展哈希代码阅读","text":"可扩展哈希一般是用在数据库中管理1条1条的record的，虽然现在很多都是用B+树了这个主要是做15-445的project时接触到的，project2需要实现1个可扩展哈希静态的哈希随着记录的增多，其冲突的概率也越来越大，此时如果能动态扩容就能优化性能了可扩展哈希的主要成员就2个，一个是bucket，它内部存放的就是1条1条的记录，一般初始化的时候就指定他的可存放记录的数目，多个bucket就构成了整个hash表第2个是directory，他是1个可以扩展的数组，每个成员都是指针，指向对应的bucket，其对应的bucket就是通过哈希函数算出对应的下标，且可能会有多个成员指向同个bucket的情况，这个后面再说还有的就是2个重要的概念：global depth和local depth，前者是directory的成员，它指明了每个bucket最大的local depth，也限制了其管理的bucket指针数组的大小，例如说global depth是5的时候，他的bucket数组最多就有32个，而local depth是每个bucket的成员，他指明了找到该bucket需要的位数，例如说 这里我分析的是https://github.com/nitish6174/extendible-hashing/blob/master/main.cpp里面的代码，内容还是比较好懂的接下来首先是他的bucket部分，这个比较简单，就是一些常规的增删查改操作， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116Bucket::Bucket(int depth, int size){ this-&gt;depth = depth; this-&gt;size = size;}int Bucket::insert(int key, string value){ std::map&lt;int,string&gt;::iterator it; it = values.find(key); if(it!=values.end()) return -1; if(isFull()) return 0; values[key] = value; return 1;}int Bucket::remove(int key){ std::map&lt;int,string&gt;::iterator it; it = values.find(key); if(it!=values.end()) { values.erase(it); return 1; } else { cout&lt;&lt;&quot;Cannot remove : This key does not exists&quot;&lt;&lt;endl; return 0; }}int Bucket::update(int key, string value){ std::map&lt;int,string&gt;::iterator it; it = values.find(key); if(it!=values.end()) { values[key] = value; cout&lt;&lt;&quot;Value updated&quot;&lt;&lt;endl; return 1; } else { cout&lt;&lt;&quot;Cannot update : This key does not exists&quot;&lt;&lt;endl; return 0; }}void Bucket::search(int key){ std::map&lt;int,string&gt;::iterator it; it = values.find(key); if(it!=values.end()) { cout&lt;&lt;&quot;Value = &quot;&lt;&lt;it-&gt;second&lt;&lt;endl; } else { cout&lt;&lt;&quot;This key does not exists&quot;&lt;&lt;endl; }}int Bucket::isFull(void){ if(values.size()==size) return 1; else return 0;}int Bucket::isEmpty(void){ if(values.size()==0) return 1; else return 0;}int Bucket::getDepth(void){ return depth;}int Bucket::increaseDepth(void){ depth++; return depth;}int Bucket::decreaseDepth(void){ depth--; return depth;}std::map&lt;int, string&gt; Bucket::copy(void){ std::map&lt;int, string&gt; temp(values.begin(),values.end()); return temp;}void Bucket::clear(void){ values.clear();}void Bucket::display(){ std::map&lt;int,string&gt;::iterator it; for(it=values.begin();it!=values.end();it++) cout&lt;&lt;it-&gt;first&lt;&lt;&quot; &quot;; cout&lt;&lt;endl;} 接下来就是directory的内容，首先是他的构造函数 123456789Directory::Directory(int depth, int bucket_size){ this-&gt;global_depth = depth; this-&gt;bucket_size = bucket_size; for(int i = 0 ; i &lt; 1&lt;&lt;depth ; i++ ) { buckets.push_back(new Bucket(depth,bucket_size)); }} 可以看到，他一开始的local depth和global depth是一样的，其哈希函数如下： 1234int Directory::hash(int n){ return n&amp;((1&lt;&lt;global_depth)-1);} 很直白的，就是取n的二进制位的最后global depth位做为哈希值，例如说当global depth为3时，上面就是n&amp;7（111）了下面是一个取pair的函数 1234int Directory::pairIndex(int bucket_no, int depth){ return bucket_no^(1&lt;&lt;(depth-1));} 这个是在桶进行split的时候调用的，这里在被调用时被分裂的桶的bucket_no+1才等于参数depth，例如说bucket_no是6（110）的时候，depth是4，那么做取异操作后，返回的是14（1110），和原来的6（0110）相比，就是在增加的哈希位上不同了，这里具体为啥这么做见后面的grow就知道了 123456void Directory::grow(void){ for(int i = 0 ; i &lt; 1&lt;&lt;global_depth ; i++ ) buckets.push_back(buckets[i]); global_depth++;} grow函数是在bucket分裂时发现他分裂后的local depth比global depth还大时调用的，调用后bucket数组翻倍，而且他翻倍后多出来的数组元素，比如说原来是n个，现在2n个，第n+1个和第1个指向同1个bucket，因为push_back会生成原来指针的副本，他也指向原来的指针所指对象，所以grow的过程并没有真正的创建bucket对象，只是多出了一些类似占位符的东西。而且看到这里上面的pairindex函数就明白了，pair指的就是这里的指针11对应的关系，bucket数组的第6个和第14个都指向同1个bucket对象，我们取得他的下标，给他赋予真正的新的bucket对象（见下面的split) 12345678910111213141516171819202122void Directory::split(int bucket_no){ int local_depth,pair_index,index_diff,dir_size,i; map&lt;int, string&gt; temp; map&lt;int, string&gt;::iterator it; local_depth = buckets[bucket_no]-&gt;increaseDepth(); if(local_depth&gt;global_depth) grow(); pair_index = pairIndex(bucket_no,local_depth); buckets[pair_index] = new Bucket(local_depth,bucket_size); temp = buckets[bucket_no]-&gt;copy(); buckets[bucket_no]-&gt;clear(); index_diff = 1&lt;&lt;local_depth; dir_size = 1&lt;&lt;global_depth; for( i=pair_index-index_diff ; i&gt;=0 ; i-=index_diff ) buckets[i] = buckets[pair_index]; for( i=pair_index+index_diff ; i&lt;dir_size ; i+=index_diff ) buckets[i] = buckets[pair_index]; for(it=temp.begin();it!=temp.end();it++) insert((*it).first,(*it).second,1);} 首先是调用要分裂的那个bucket的increasedepth函数，他的local depth+1了，如果需要扩容调用grow函数，接着是找到指向同1个bucket的bucket_no(pairindex函数)，然后在他上面真正的创建1个新的bucket，然后把需要分裂的那个桶的内容赋值给temp变量并清空，准备后面的分配，而接下来的操作则是bucket数组里的某几个指向新建立的bucket，这里我们具体以一个例子说明假设一开始global depth和local depth都是3，后来有某个桶7（111）他要split，发现global depth不够，于是需要grow，然后就走上述流程，接着算出index_diff和dir_size都是16，pair_index是15（1111），那么很明显2个for循环都不满足条件不执行，因为除了7和15外就没有哪个bucket_no指向相关的桶了，但假如后来桶7（0111，这个时候是4层了）又不够了，又要扩容了，global depth就变成5了，一切如上照旧；后来桶7又不够用。又分裂了，global depth变为6了，不过这个时候和原来8个桶相比，只多了3个桶而已到了后面，终于是1个local depth是3的桶要分裂了，假设他是6（110），他发现global depth够用，就不用grow了，他的pair_index是14（1110），index_diff是16，dir_size是64，第1个for没走，但第2个，他会遍历30（011110），46（101110），62（111110），这3个桶都指向新分裂出来的桶，原本他们指向的和6一样的桶，至于为啥这么做，我的想法是，当global depth比local depth多到1定程度时，指向同1个桶的哈希下标是有很多的，这个时候就需要新生成的桶来分担一些，例如上面的6，在没分裂前，后3位是110的桶的下标都指向了6,的桶，分裂后，后四位是0110的依旧，但1110的则被分配去新的桶了，假如不这么做的话，到后面可能就出现某些桶需要频繁地分裂的结果接下来就是insert函数，其实现如下 123456789101112131415161718192021void Directory::insert(int key,string value,bool reinserted){ int bucket_no = hash(key); int status = buckets[bucket_no]-&gt;insert(key,value); if(status==1) { if(!reinserted) cout&lt;&lt;&quot;Inserted key &quot;&lt;&lt;key&lt;&lt;&quot; in bucket &quot;&lt;&lt;bucket_id(bucket_no)&lt;&lt;endl; else cout&lt;&lt;&quot;Moved key &quot;&lt;&lt;key&lt;&lt;&quot; to bucket &quot;&lt;&lt;bucket_id(bucket_no)&lt;&lt;endl; } else if(status==0) { split(bucket_no); insert(key,value,reinserted); } else { cout&lt;&lt;&quot;Key &quot;&lt;&lt;key&lt;&lt;&quot; already exists in bucket &quot;&lt;&lt;bucket_id(bucket_no)&lt;&lt;endl; }} 首先是计算哈希值，例如说上面的例子继续下去，此时的global depth是6，这里根据上面的例子，对于后4位是1110的，他们会指向同1个桶，而后4位是0110的，他们会指向另外1个桶，可万一他原本就要溢出的桶里面，每条记录的后4位都是0110呢，这个时候他们就都走到同1个桶了，就又溢出了，这个时候上面代码就根据insert的返回值判断是否溢出，溢出了，则要对bucket_no这个桶再一次split，例如说我们假设的6（0110，现在是4位local depth），6的pair index这个时候是22了（10110），split也顺带把54指向了新生成的桶（110110，接下来就是根据5位二进制去判断了，因为我们原本假设他们后4位都是0110，现在就进一步地根据第5位是0还是1去判断走哪个桶了，如果还溢出，就继续分裂，知道没有溢出为止。总结目前上述内容，就是一种平衡吧，当global depth是6的时候，在6（110）这个下标的桶还没分裂前，有8个哈希下标会指向他，分裂的同时也应该能使得new出来的桶分担一些那接下来有分必有合，shrink操作函数如下 123456789101112131415void Directory::shrink(void){ int i,flag=1; for( i=0 ; i&lt;buckets.size() ; i++ ) { if(buckets[i]-&gt;getDepth()==global_depth) { flag=0; return; } } global_depth--; for(i = 0 ; i &lt; 1&lt;&lt;global_depth ; i++ ) buckets.pop_back();} 如果有1个桶的local depth和global depth一样，就无法缩小了，原因可以看到后面他缩小的操作，实际上就是把后半部分的bucket给去掉了，而能没有后果的去掉的前提是，这些bucket指向的对象完全和前半部分的一样，但假如其中某个桶的local depth和global depth一样，说明是经过了split中的new Bucket(local_depth,bucket_size)操作，导致这后半部分有某个桶他指向了新的对象，也就无法删除了，下面是merge函数 1234567891011121314151617181920void Directory::merge(int bucket_no){ int local_depth,pair_index,index_diff,dir_size,i; local_depth = buckets[bucket_no]-&gt;getDepth(); pair_index = pairIndex(bucket_no,local_depth); index_diff = 1&lt;&lt;local_depth; dir_size = 1&lt;&lt;global_depth; if( buckets[pair_index]-&gt;getDepth() == local_depth ) { buckets[pair_index]-&gt;decreaseDepth(); delete(buckets[bucket_no]); buckets[bucket_no] = buckets[pair_index]; for( i=bucket_no-index_diff ; i&gt;=0 ; i-=index_diff ) buckets[i] = buckets[pair_index]; for( i=bucket_no+index_diff ; i&lt;dir_size ; i+=index_diff ) buckets[i] = buckets[pair_index]; }} 这里就是split反过来，例如说上面的例子，我想merge22，他的pair index是6，且他们的local depth都是5，这个时候就可以走if里面的流程，把这个local depth减1，然后删去22这个桶，且让6所指的桶的指针给了22，然后就是把那些原来指向22的桶现在指向6，就是和上面split一样的思路下面是remove函数 123456789101112131415void Directory::remove(int key,int mode){ int bucket_no = hash(key); if(buckets[bucket_no]-&gt;remove(key)) cout&lt;&lt;&quot;Deleted key &quot;&lt;&lt;key&lt;&lt;&quot; from bucket &quot;&lt;&lt;bucket_id(bucket_no)&lt;&lt;endl; if(mode&gt;0) { if(buckets[bucket_no]-&gt;isEmpty() &amp;&amp; buckets[bucket_no]-&gt;getDepth()&gt;1) merge(bucket_no); } if(mode&gt;1) { shrink(); }} mode是用户输入的，根据他来判断是要merge（删去某个桶）还是直接对半砍去剩下的几个没列出来的也只是很简单的操作，这个代码也就分析完咯，下面就开始做project2捏","link":"/2022/09/07/%E4%B8%80%E4%B8%AA%E5%8F%AF%E6%89%A9%E5%B1%95%E5%93%88%E5%B8%8C%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/"},{"title":"引用折叠","text":"所谓的万能引用主要是用在以下2种场合：第1种是模板如下： 12template&lt;typename T&gt;void func(T&amp;&amp; t){...} 以上代码中的&amp;&amp;并不是右值引用的意思，他是表示说这个t肯定是一个引用类型，但具体是左值引用还是右值引用我们得根据传进来的参数确定那如何根据传进来的参数确定呢，这里就用到了引用折叠了，具体而言，当T被推导出来是右值时，T&amp;&amp;是一个右值引用（&amp;&amp; &amp;&amp; 折叠为了&amp;&amp;），而其他情况都是折叠为&amp;，即左值引用为了验证，我们可以用完美转发来验证一下 12345678910111213141516171819202122#include &lt;iostream&gt;void print(int&amp; t){ std::cout &lt;&lt; &quot;left&quot; &lt;&lt; std::endl;}void print(int&amp;&amp; t){ std::cout &lt;&lt; &quot;right&quot; &lt;&lt; std::endl;}template&lt;typename T&gt;void func(T&amp;&amp; t){ print(std::forward&lt;T&gt;(t));}int main(){ int x = 10; func(x); func(12); func(std::move(x)); int&amp; y = x; func(y);} 以上代码第1个显示是left，x是一个左值为什么被推导为左值引用呢，因为在func的参数里，传进来的T&amp;&amp;必须被解释为1个引用，那T就可以是int，int&amp;，int&amp;&amp;，只有int&amp;能被推断为左值(int&amp; &amp;&amp;折叠为&amp;)，第2个则是right，T是实例化为int，第3个为right，T为int&amp;&amp;，第4个T为int&amp;，折叠为&amp;，所以结果是left 第2种使用万能引用的场合是在auto推断中，如 12auto&amp;&amp; i = 3； //auto推断为int，i为int&amp;&amp;类型，即右值引用auto&amp;&amp; j = i; // auto推断为int&amp;，i为int&amp;，即左值引用","link":"/2022/09/07/%E5%BC%95%E7%94%A8%E6%8A%98%E5%8F%A0/"},{"title":"函数返回类型后置","text":"返回类型后置，主要的用处在于某些函数他返回的类型可能很复杂，例如返回一个函数指针等，如下 12typedef void(* ret)(int,double);ret myfunc(){...} 为了更加简洁，我们可以这么写 123auto myfunc() -&gt; void(*)(int,double){ ...} 其中的auto只是个占位符，真正的返回类型在后面，感觉和Python的写法很像捏 除此之外，我们还可以用decltype来推导函数的返回类型，如下： 1234template&lt;typename T1, typename T2&gt;auto func(T1 t1, T2 t2)-&gt;decltype(t1 + t2){ return t1 + t2;} 那么生成的模板函数就会根据t1+t2的实际类型决定返回类型了c++也允许decltype放在函数名之前表示返回类型如下： 1234template&lt;typename T1, typename T2&gt;decltype(T1() + T2()) func(T1 t1, T2 t2){ return t1 + t2;} 这么写虽然说也可以，但实际不这么建议使用，1是他需要要求T1和T2有无参构造函数，2是不够简洁","link":"/2022/09/07/%E5%87%BD%E6%95%B0%E8%BF%94%E5%9B%9E%E7%B1%BB%E5%9E%8B%E5%90%8E%E7%BD%AE/"},{"title":"4种c++风格的类型转换","text":"reinterpret_cast(value),他可以把一个指针转化为另外1种指针，也可以把1个整型值赋给一个指针，其最本质在于不修改value的底层二进制位，只是修改了去解释他的方法，比如说同一个二进制数，我用整数补码（int）和float类型那个ieee标准去解释结果肯定不同 123456789#include &lt;iostream&gt;int main(){int a = 0;int* p = &amp;a;char* p2 = reinterpret_cast&lt;char *&gt;(p);*p2 = '1';std::cout &lt;&lt; a &lt;&lt; std::endl;} 上面代码的输出结果为49，正好是a的asci值，首先他会把p这个int指针强制转换为char类型的指针，而且他指向了a的最低位（在我们机器上是小端存储的的），我们解引用赋值，其实就是在a的最低位字节上赋值了整数49，当用char的方式去解读时读出来的就是’a’,int则是49了，还有另外一种使用方式就是把一个整数赋值给一个指针，然后这个指针就指向这个地址了， 123int* p;int address = 0x12345678;p = reinterpret_cast&lt;int*&gt;(address); 当然这种得是你能访问这个地址才行 而这种强制转换在leveldb中的fixedint编码中就使用了，如下： 1234567inline void EncodeFixed32(char* dst, uint32_t value) { uint8_t* const buffer = reinterpret_cast&lt;uint8_t*&gt;(dst); buffer[0] = static_cast&lt;uint8_t&gt;(value); buffer[1] = static_cast&lt;uint8_t&gt;(value &gt;&gt; 8); buffer[2] = static_cast&lt;uint8_t&gt;(value &gt;&gt; 16); buffer[3] = static_cast&lt;uint8_t&gt;(value &gt;&gt; 24);} 首先他把dst这个指针重新解释为1个指向uint8_t类型的指针然后赋值给buffer，现在buffer和dst指向同一个内存地址了，只不过他们解释这个地址里的东西的方式不同了，然后就是依次把value的每个字节的值写入buffer，也就是dst中，decode的则是反过来 123456789inline uint32_t DecodeFixed32(const char* ptr) { const uint8_t* const buffer = reinterpret_cast&lt;const uint8_t*&gt;(ptr); // Recent clang and gcc optimize this to a single mov / ldr instruction. return (static_cast&lt;uint32_t&gt;(buffer[0])) | (static_cast&lt;uint32_t&gt;(buffer[1]) &lt;&lt; 8) | (static_cast&lt;uint32_t&gt;(buffer[2]) &lt;&lt; 16) | (static_cast&lt;uint32_t&gt;(buffer[3]) &lt;&lt; 24);} 然后就是static_cast,基本等价于隐式转换，可以用在空指针转化为任意指针，可以用在整形和浮点数之间，对于继承的机制来说，可以把子类转化为父类，父类则不能反过来变为子类的， const_cast const_cast 运算符仅用于进行去除 const 属性的转换，它也是四个强制类型转换运算符中唯一能够去除 const 属性的运算符。它的使用场景我目前了解的具体是在与const string这种相关的函数签名上，具体而言，大家都知道只有const string &amp;才能引用一个右值（在不想写右值引用的情况下），而为了能让函数能接受(“ww”,”ee”)这种参数，我们就不得不把函数的参数声明为const string&amp;，那这个时候他就很有可能也返回一个const string &amp;，但往往我们并不需要这种const的限制，所以我们就可以写个没有cosnt约束的函数，在其内部使用const_cast添加或移去他的常量性，如下： 1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;const string &amp; shorter(const string &amp; s1, const string &amp; s2){ cout &lt;&lt;&quot; this is const&quot; &lt;&lt; endl; return s1;}string &amp; shorter(string &amp; s1, string &amp; s2){ cout &lt;&lt;&quot;this is non const&quot; &lt;&lt; endl; auto &amp;res = shorter(const_cast&lt;const string &amp;&gt;(s1), const_cast&lt;const string &amp;&gt;(s2)); return const_cast&lt;string &amp;&gt;(res);}int main(){ string s1(&quot;ww&quot;); string s2(&quot;Ee&quot;); shorter(s1,s2); shorter(&quot;ww&quot;,&quot;ee&quot;);} 这样子不管进来的是什么样的内容，就都能处理了， dynamic_cast专门用于将多态基类的指针或引用强制转换为派生类的指针或引用，而且能够检查转换的安全性。对于不安全的指针转换，转换结果返回 NULL 指针。 dynamic_cast 是通过“运行时类型检查”来保证安全性的。dynamic_cast 不能用于将非多态基类的指针或引用强制转换为派生类的指针或引用——这种转换没法保证安全性，只好用 reinterpret_cast 来完成。","link":"/2022/09/09/4%E7%A7%8Dc-%E9%A3%8E%E6%A0%BC%E7%9A%84%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/"},{"title":"CRTP与静态多态","text":"CuriouslyRecurringTemplatePattern，简称CRTP，是一种实现静态多态的机制，简单而言，他的核心在于：父类是一个模板类，派生类会继承父类，且以派生类自身作为父类的模板参数，如下： 123456789101112131415161718192021222324252627template&lt;typename T&gt;class Base{public: void print(){ static_cast&lt;T*&gt;(*this)-&gt;imp(); } void imp(){ std::cout &lt;&lt; &quot;this is base&quot; &lt;&lt; std::endl; }};class Son1: public Base&lt;Son1&gt;{ void imp(){ std::cout &lt;&lt; &quot;this is son 1&quot; &lt;&lt; std::endl; }};class Son2: public Base&lt;Son2&gt;{ void imp(){ std::cout &lt;&lt; &quot;this is son 2&quot; &lt;&lt; std::endl; }};template&lt;typename T&gt;void func(T &amp; t){ t.print();} 当我传入func的对象是Son1时， Base实例化为Son1，print中的static_cast就会把this指针强制转换为Son1*，也就能调用Son1自己实现的函数了，不过这里严格意义上来说并不算是多态，因为每个派生类继承的是各自实例化后的模板类，使用static_cast就能把从基类去访问派生类的成员函数了似乎llvm的visitor模式采用的就是这种捏，tvm中的貌似也有涉及这种设计，后续再看","link":"/2022/09/09/CRTP%E4%B8%8E%E9%9D%99%E6%80%81%E5%A4%9A%E6%80%81/"},{"title":"leveldb源码系列1-skiplist","text":"本文分析的是leveldb中的跳表skip list的实现，他会把user key和user value打包成一个更大的key塞入list中跳表的一个例子如下图 可以看到，每一个node，它都有不同的高度，且每个节点都在第0层都有出现，第0层就像最简单的链表一样，而到了上面的层数节点的个数越来越少，就像树状结构那种，跳表的许多操作都能在logn的复杂度下完成，leveldb的主要结构包括skiplist，内部是由一系列的node构成的，他还实现了一个iterator用于遍历接下来首先看node的实现 1234567891011121314151617181920212223242526272829303132333435363738template &lt;typename Key, class Comparator&gt;struct SkipList&lt;Key, Comparator&gt;::Node { explicit Node(const Key&amp; k) : key(k) {} Key const key; // Accessors/mutators for links. Wrapped in methods so we can // add the appropriate barriers as necessary. Node* Next(int n) { assert(n &gt;= 0); // Use an 'acquire load' so that we observe a fully initialized // version of the returned Node. return next_[n].load(std::memory_order_acquire); } void SetNext(int n, Node* x) { assert(n &gt;= 0); // Use a 'release store' so that anybody who reads through this // pointer observes a fully initialized version of the inserted node. next_[n].store(x, std::memory_order_release); } // No-barrier variants that can be safely used in a few locations. Node* NoBarrier_Next(int n) { assert(n &gt;= 0); return next_[n].load(std::memory_order_relaxed); } void NoBarrier_SetNext(int n, Node* x) { assert(n &gt;= 0); next_[n].store(x, std::memory_order_relaxed); } private: // Array of length equal to the node height. next_[0] is lowest level link. // 1) 这里提前声明并申请了一个内存，用于存储第 0 层的数据，因为第 0 层必然存在数据。 // 2) 这里的数组长度其实就是层高，假设 next_ 长度为 n，那么就会从 next_[n-1] 开始查找。 // 3) 因为 skip list 的 level 并不会太大，使用数组存储 Node 指针的话对 CPU 内存更友好 // https://15721.courses.cs.cmu.edu/spring2018/papers/08-oltpindexes1/pugh-skiplists-cacm1990.pdf std::atomic&lt;Node*&gt; next_[1];}; 第一部分主要是1个显式的构造函数，指定某个键并初始化key这个成员数据，然后是他的next_数组，这个数组主要是用来存放该结点的每一层的next结点的指针的，指定为1是因为必然要在第0层有该结点，接下来是他的2个无锁操作和2个不用内存屏障的操作，next这个无锁操作使用了next_这个原子对象的load函数，且指定了memory_order_acquire,那么在这个语句之前的都不会被重排到他后面了，而setnext则是store函数，指定了memory_order_release，则该语句后面的内容都不会重排到他前面去，后面的2个则是使用了memory_order_relaxed,他只保证这条语句他是原子的，语句前后怎么重排都没有限制接下来是一个生成新结点的函数 123456789template &lt;typename Key, class Comparator&gt;typename SkipList&lt;Key, Comparator&gt;::Node* SkipList&lt;Key, Comparator&gt;::NewNode( const Key&amp; key, int height) { // 内存分配时只需要再分配 level - 1 层，因为第 0 层已经预先分配完毕了。 char* const node_memory = arena_-&gt;AllocateAligned( sizeof(Node) + sizeof(std::atomic&lt;Node*&gt;) * (height - 1)); // 这里是 placement new 的写法，在现有的内存上进行 new object return new (node_memory) Node(key);} 第2行开头的typename是为了告诉编译器，后面这个::Node是一个类型，那么整个函数的返回值就是NOde*了，首先分配内存，然后在这个内存上placement new，调用node的构造函数了 接下来是skiplist的成员函数第一个是生成随机层数的函数 123456789101112template &lt;typename Key, class Comparator&gt;int SkipList&lt;Key, Comparator&gt;::RandomHeight() { // Increase height with probability 1 in kBranching static const unsigned int kBranching = 4; int height = 1; while (height &lt; kMaxHeight &amp;&amp; ((rnd_.Next() % kBranching) == 0)) { height++; } assert(height &gt; 0); assert(height &lt;= kMaxHeight); return height;} 首先初始化height为1，接着以1/4的概率使得while成立（在height比kmaxheight小的情况下），这样子第1层的node个数就大致是第0的1/4了，后面的层数以此类推，而用1/4这个概率貌似也是提出跳表的论文中建议的？接下来是一个key的大小顺序的函数 12345template &lt;typename Key, class Comparator&gt;bool SkipList&lt;Key, Comparator&gt;::KeyIsAfterNode(const Key&amp; key, Node* n) const { // null n is considered infinite return (n != nullptr) &amp;&amp; (compare_(n-&gt;key, key) &lt; 0);} 当要比较的对象（比如说是next节点指向的某一层对象）不为空且compare比较器得到的结果小于0时，说明这个key在顺序上是在n后面的， 接下来就是查找在每一层上 12345678910111213141516171819202122232425template &lt;typename Key, class Comparator&gt;typename SkipList&lt;Key, Comparator&gt;::Node*SkipList&lt;Key, Comparator&gt;::FindGreaterOrEqual(const Key&amp; key, Node** prev) const { Node* x = head_; int level = GetMaxHeight() - 1; while (true) { /* 获取当前 level 层的下一个节点 */ Node* next = x-&gt;Next(level); if (KeyIsAfterNode(key, next)) { // Keep searching in this list x = next; } else { // prev 数组主要记录的就是每一层的 prev 节点，主要用于插入和删除时使用 if (prev != nullptr) prev[level] = x; if (level == 0) { return next; } else { // Switch to next list level--; } } }} 其中的GetMaxHeight函数获取的是当前结点的层数，我们从这个节点的最高层开始找，不断获取他的next节点，判断这个node他","link":"/2022/09/09/leveldb%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%971-skiplist/"},{"title":"tvm系列1——te代码阅读","text":"这篇是想探索一下tvm的te的compute和schedule具体的实现代码， 1234n = te.var(&quot;n&quot;)A = te.placeholder((n,), name=&quot;A&quot;)B = te.placeholder((n,), name=&quot;B&quot;)C = te.compute(A.shape, lambda i: A[i] + B[i], name=&quot;C&quot;) 上面这段假如熟悉tvm的应该再熟悉不过了，首先第1句话，返回的是tvm.tir.Var的数据类型的变量，这个是tir上的数据结构，后面再解析下面的A和B的placeholder如下 1234def placeholder(shape, dtype=None, name=&quot;placeholder&quot;): shape = (shape,) if isinstance(shape, tvm.tir.PrimExpr) else shape dtype = &quot;float32&quot; if dtype is None else dtype return _ffi_api.Placeholder(shape, dtype, name) 这个tvm.tir.PrimExpr是tir大多数类的父类，然后就会调用ffi机制去使用c++写的代码，这里也没啥可以说的，返回的就是 到了compute，这里源码的一开始一大段都是处理参数变量名称的，不用理会，这里他会if else到最后，直接把argspec.args当做arg——names，这里他是使用inspect的getfullargspec去获取一个lambda表达式的所有信息的到下面dim_var = [tvm.tir.IterVar((0, s), x, 0) for x, s in zip(arg_names, shape[:out_ndim])] body = fcompute(*[v.var for v in dim_var]) out_ndim是第1个参数的维度，这里是1，然后s是只有1个，就是n，会用他们去构造IterVar，第1个参数是这个iter的范围，第2个是这个iter的标识，第3个是这个iter的类型，源码中写着他是datapar，应该是一般的那种iter这里构造出来的dim_var打印如下： 12~~~接下来的body部分的var其实就是上面的第2个参数，fcompute就是C中的lambda表达式，首先把var的列表给解包，在调用fcompute这个可调用对象，就是上面C的lambda表达式，这里我们再写1个看看 n = te.var(“n”)A = te.placeholder((n,n), name=”A”)B = te.placeholder((n,n), name=”B”)C = te.compute(A.shape, lambda i,j: A[i,j] + B[i,j], name=”C”) 这里返回的body的类型是tvm.tir.expr.Add,主要是因为A和B都是tvm.te.Tensor,他们继承自ExprOp类，而这个类又写了一堆魔法方法，重载了一系列的运算符，比如说这里的+运算符，写了__add__函数后，最终调用这个函数 假如说在compute中，有te.sum这种reduce操作的，还会识别出其中达到reduce_axis,","link":"/2022/09/08/tvm%E7%B3%BB%E5%88%971%E2%80%94%E2%80%94te%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"c+2","slug":"c-2","link":"/tags/c-2/"},{"name":"tvm","slug":"tvm","link":"/tags/tvm/"},{"name":"小组件","slug":"小组件","link":"/tags/%E5%B0%8F%E7%BB%84%E4%BB%B6/"},{"name":"leveldb","slug":"leveldb","link":"/tags/leveldb/"}],"categories":[]}