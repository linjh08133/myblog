{"pages":[],"posts":[{"title":"test","text":"","link":"/2022/09/02/test/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/09/02/hello-world/"},{"title":"test1","text":"","link":"/2022/09/02/test1/"},{"title":"tvm","text":"this is a placeholder for tvm下面测试以下图片捏","link":"/2022/09/04/tvm/"},{"title":"类型萃取","text":"所谓的类型萃取，就算说在某些函数模板中，它需要知道传进来的变量，它的类型到底是啥，用于返回值这类的，但c++是不允许说推导出返回值类型的，例如以下代码是不可能通过编译的template&lt;typename T&gt; (*T) func(T t){ ... }为了解决这种问题，对于我们自定义的类，可以利用typedef去声明，如下 1234567891011template&lt;typename T&gt;struct MyIter{ typedef T value_type; T * ptr; MyIter(T* p):ptr(p){} T&amp; operator*() { return *ptr; }};template&lt;typename T&gt;typename T::value_type func(T t){ std::cout &lt;&lt; *t &lt;&lt; std::endl;} 这样做当传入类型是MyIter&lt;int&gt;的时候，首先MyIter的T会实例化为int,func这个函数模板的T会被实例化为MyIter，那么其返回类型也就是int了，这里的typename是告诉编译器，后面的T::value_type 是一个类型（像int，double这种),不加就可能会被当作是成员变量造成歧义。那当我们传入的是原生指针呢，上面的自定义对象我们可以直接获取它的成员变量的所指对象，但int * 这种就无法通过T::value_type,因为它根本就没有，所以这个时候就可以利用模板偏特化+trait的技巧了，如下 123456789101112131415161718192021template\\&lt;typename T\\&gt;struct MyIter{ typedef T value_type; T * ptr; MyIter(T* p):ptr(p){} T&amp; operator*() { return *ptr; }};template\\&lt;typename T\\&gt;struct iterator_traits{ typedef T::value_type value_type;};template\\&lt;typename T\\&gt;struct iterator_traits\\&lt;T*\\&gt;{ typedef T value_type;};template&lt;typename T&gt;typename iterator_traits&lt;T&gt;::value_type func(T t){ std::cout &lt;&lt; *t &lt;&lt; std::endl; 那么当func传进来的是int *的时候，会调用特例化的第2个模板，那么value_type就是int啦，这样做iterator所指类型不管是什么情况都能知道了，","link":"/2022/09/04/%E7%B1%BB%E5%9E%8B%E8%90%83%E5%8F%96/"},{"title":"内存模型1.md","text":"c++的内存模型挺复杂的，因为现代cpu架构的原因，例如cache等，一些操作我们无法得知他具体什么时候会对其他线程可见，例如说thread A写了一个全局变量，但它很有可能是写到自己的私有cache导致说它的这个写对其他thread不可见，那么c++对于这些就提出了一个叫内存模型的玩意。首先是顺序一致性模型，它规定有2点：1.内存访问执行的顺序与程序指定的顺序相同2.所有核心的内存访问实际执行顺序都和程序指定顺序相同有1个例子就可以说明这个，一个群聊里，每个人的发言记录的顺序是固定的，不可能说先看到晚发出去的信息，而他所看到的所有人的发言记录，与其他的每个人都一样，都是遵循着某种交叉着的顺序，而且大家观察到的顺序都是一样的，而c++默认就是使用这种内存模型，即memory_order_seq_cst,以下面这段代码为例 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;#include &lt;iostream&gt;std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x(){ x.store(true,std::memory_order_seq_cst); // 1}void write_y(){ y.store(true,std::memory_order_seq_cst); // 2}void read_x_then_y(){ while(!x.load(std::memory_order_seq_cst)); if(y.load(std::memory_order_seq_cst)) // 3 ++z; //std::cout &lt;&lt; z &lt;&lt; std::endl;}void read_y_then_x(){ while(!y.load(std::memory_order_seq_cst)); if(x.load(std::memory_order_seq_cst)) // 4 ++z; //std::cout &lt;&lt; z &lt;&lt; std::endl;}int main(){ x=false; y=false; z=0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load()!=0); // 5 std::cout &lt;&lt; z &lt;&lt; std::endl;} 这里assert永远不会报错，且下一步输出的z有可能是1，有可能是2，下面分别分析：如果第1个load是true，但第2个load是false，也就算说它观察到了x的store是先于y的store，或者说在它跳出while的时候，肯定是看到了x的store操作，但y的load还是false，说明它没观察到y的store操作，所以它观察到的所x的store先于y的store，那么对thread d而言，它也必须以这种顺序观察到2个store，所以说thread d的第1个load如果是true了，说明它观察到了y的store，所以它必然已经观察到了x的store，所以它下一步的load必然为true，反过来也同理，这个时候的z就是1了而z=2的情况为还不是很明白，假如说a的第一个load到了某个时间点，观察到了x的store，它退出了while，然后它第2个load，观察到了y是true，但这就没办法确定x和y的store的观察顺序了，如果x的store先于y，那么对d而言，它的2个load必然为ture，z=2，如果y的store是先于x的，那么thread d就可能第2个load是false了，此时z=1（这里好像就是第1种情况了？，这里的解释不一定正确） 接下来是acq-rel模型，它解除了对全局一致性的约束，只单纯地利用memory_order_acquire和memory_order_release,前者如果某个load使用则在load之前的指令都不能跨过该语句被重排到后面，后者则是某个store使用则其后语句不能被重排跨到前面我们经常利用他们去实现同步操作，但是这里要注意，它无法保证全局一致，也就是说，每个thread观测到的顺序是可能不一样的，如下例子： 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x(){ x.store(true,std::memory_order_release);}void write_y(){ y.store(true,std::memory_order_release);}void read_x_then_y(){ while(!x.load(std::memory_order_acquire)); if(y.load(std::memory_order_acquire)) // 1 ++z;}void read_y_then_x(){ while(!y.load(std::memory_order_acquire)); if(x.load(std::memory_order_acquire)) // 2 ++z;}int main(){ x=false; y=false; z=0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load()!=0); // 3} 对于不同thread的对同1个原子变量，acq-rel的语义只能做到——如果在load的时候观察到了store，那么必然就能保证我们需要的同步，如果在load的时候还没观察到store的话就做不到了，如下代码 1234567891011121314151617181920212223242526272829303132#include &lt;thread&gt;#include &lt;atomic&gt;#include &lt;cassert&gt;#include &lt;string&gt;#include &lt;iostream&gt;#include &lt;chrono&gt;std::atomic&lt;std::string*&gt; ptr ;int data; void producer(){ std::this_thread::sleep_for(std::chrono::milliseconds(1000)); std::string* p = new std::string(&quot;Hello&quot;); data = 42; ptr.store(p, std::memory_order_release);} void consumer(){ std::string* p2 = nullptr; //std::this_thread::sleep_for(std::chrono::milliseconds(1000)); p2 = ptr.load(std::memory_order_acquire); assert(*p2 == &quot;Hello&quot;); // never fires assert(data == 42);} int main(){ std::thread t1(producer); std::thread t2(consumer); t1.join(); t2.join();} 这段代码大多数时候是报错的，因为thread 1 sleep了一段时间，所以在第2个thread中，在它load的时候，第1个thread的store因为sleep的原因未执行，导致了它无法做到同步，所以下面的assert必然报错，但如果修改p2，改成while(!p2=ptr.load(std::memory_order_acquire)),就能实现同步了，因为它会一直在while中循环，直到某1次循环中，它观察到了线程1的store操作，那么这2者的同步语义就能建立起来了——线程1的store之前的语句必然先于store，线程2的load之后的语句必然非先于load，而它跳出循环的时候store必然是已经被观测到了，所以这种同步就建立起来了回头看上一段代码，这段代码可能报错的原因就在于，acq-rel语义没有规定全局一致，那么就可能出现thread c观测到x的store先于y的store，而d则反过来，此时他们就都加不了z，或者说我们可以这么理解——全局一致下，c看到了x是true，y只load1次看到是false，说明x的store对d来说也必然先于y的store，而d一直卡在while那里，直到它观测到y是true；但没有全局一致的要求时，以下情况就可能发生——对thread c，它卡在while一段时间退去后，此时它肯定观测到了x的sotre，而它只对y进行了1次load，是false，说明它观测到x的store先于y，但对d而言，没有全局一致的约束，c的观测顺序对它没意义了，它完全可以一直卡在while，直到它观测到y的store，然后在对x进行1次load，发现x的store还没被观察到，对d而言，它是先观测到y后才是x，那么这种矛盾的原因在于，x和y的store它可能是写入内存，而c和d在load的时候，不一定去内存找，它可能直接在自己的cache中找，不一致就来了那么怎么修改这段代码呢，很简单，只要保证x和y他们的被观测到的顺序是一样的就可以了，上述由于是分开被2个线程写的原因如下 123456789101112131415161718192021222324252627#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x_then_y(){ x.store(true,std::memory_order_relaxed); // 1 y.store(true,std::memory_order_release); // 2}void read_y_then_x(){ while(!y.load(std::memory_order_acquire)); // 3 自旋，等待y被设置为true if(x.load(std::memory_order_relaxed)) // 4 ++z;}int main(){ x=false; y=false; z=0; std::thread a(write_x_then_y); std::thread b(read_y_then_x); a.join(); b.join(); assert(z.load()!=0); // 5} 这里就不用解释了，但如果说y的load不是while，而是只读1次，那这种同步性就没有了，因为它完全有可能在load之前没有观察到store，加上while，不断的load，直到某1次，发现y被store为true了，这次的load就和store有了先后顺序了，那么就可以保证同步了","link":"/2022/09/05/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B1/"},{"title":"模板偏特化","text":"","link":"/2022/09/04/%E6%A8%A1%E6%9D%BF%E5%81%8F%E7%89%B9%E5%8C%96-1/"},{"title":"模板偏特化","text":"模板偏特化，就","link":"/2022/09/04/%E6%A8%A1%E6%9D%BF%E5%81%8F%E7%89%B9%E5%8C%96/"},{"title":"shared_ptr线程安全","text":"shared_ptr众所周知的智能指针，其允许多个指针指向同一内存对象，且在引用计数为0的时候自动析构被管理的对象，但是，在多线程的环境下，他的操作不是线程安全的，原因在于，其管理对象的方式是通过指针去管理，而其底层的引用计数本身也是一个指针，指向一个真正的计数对象，当我们执行如下代码的时候 12shared_ptr&lt;A&gt; a1 (new A));shared_ptr&lt;A&gt; a2 = a1; a2在构造的时候，是分为2步的，第1步是让a2管理的A对象指向a1管理的对象，第2步是让a2的引用计数也指向a1的引用计数对象，然后再把count+1那么这种非原子的操作方式就可能带来race condition了，如下代码 1234567891011121314151617181920212223#include &lt;memory&gt;#include &lt;iostream&gt;#include &lt;thread&gt;std::shared_ptr&lt;int&gt; p1 (new int(5));void func1(){ std::shared_ptr&lt;int&gt; p2; p2 = p1; std::cout &lt;&lt; *p2 &lt;&lt; std::endl;}void func2(){ std::shared_ptr&lt;int&gt; p3; p1 = p3;}int main(){ std::thread t1(func1); std::thread t2(func2); t1.join(); t2.join();} 当线程1执行p2 = p1的时候，首先他会把p1管理对象的指针赋值给p2，但这个时候，线程2来了，他的p1 = p3的赋值操作，导致p1原来管理的int(5)变成了1个没人指向的对象，所以其对应的引用计数也为0，且这个原来的对象就被析构了，此时p1所指的引用计数对象，他的count是2，再下一步，来到线程1，p2 = p1指令继续赋值，把p1的新的引用计数对象赋给了p2，那么这个引用计数对象的count就是3了，但此时p2所指的是那个已经被析构了的int(5),这个时候我们再解引用p2，就会报错了，如图：中间的那个偶尔的段错误吐核就是啦所以这里要记住：shared_ptr的实现机制，最核心的就是使用2个指针，指向1个被管理对象和1个与之关联的引用计数对象，在赋值的时候是分2步的非原子操作，所以这个时候一定要加锁使其原子化","link":"/2022/09/05/shared-ptr%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"},{"title":"局部静态对象","text":"c++11规定，在一个函数内的局部静态变量(local static),它的初始化是必须线程安全的，也就是说，它的初始化过程是加锁的，其他线程在其初始化过程中是被阻塞的，否则就可能说1个线程在初始化过程中在还没赋值之前，另1个线程也开始初始化，最后就造成了重复构造，具体如下代码 123456789101112131415161718192021222324252627282930#include &lt;thread&gt;#include &lt;iostream&gt;#include &lt;mutex&gt;class A {public:A(){ std::cout &lt;&lt; &quot;constructing&quot; &lt;&lt; std::endl; }};A&amp; getA(){ static A a; return a;}std::mutex lock;void func(){ A a = getA(); std::unique_lock&lt;std::mutex&gt; mylock (lock); std::cout &lt;&lt; &amp;a &lt;&lt; std::endl;}int main(){ std::thread thread_list[10]; for (int i = 0; i &lt; 10; i++){ thread_list[i] = std::thread(func); } for (int i = 0; i &lt; 10; i++){ thread_list[i].join(); }} 可以看到，这个对象只被正确地构造了1次，其他线程都引用同一个对象这种方式是c++实现单例模式的最佳手段，因为它就是这么简单","link":"/2022/09/05/%E5%B1%80%E9%83%A8%E9%9D%99%E6%80%81%E5%AF%B9%E8%B1%A1/"},{"title":"一个可扩展哈希代码阅读","text":"可扩展哈希一般是用在数据库中管理1条1条的record的，虽然现在很多都是用B+树了这个主要是做15-445的project时接触到的，project2需要实现1个可扩展哈希静态的哈希随着记录的增多，其冲突的概率也越来越大，此时如果能动态扩容就能优化性能了可扩展哈希的主要成员就2个，一个是bucket，它内部存放的就是1条1条的记录，一般初始化的时候就指定他的可存放记录的数目，多个bucket就构成了整个hash表第2个是directory，他是1个可以扩展的数组，每个成员都是指针，指向对应的bucket，其对应的bucket就是通过哈希函数算出对应的下标，且可能会有多个成员指向同个bucket的情况，这个后面再说还有的就是2个重要的概念：global depth和local depth，前者是directory的成员，它指明了每个bucket最大的local depth，也限制了其管理的bucket指针数组的大小，例如说global depth是5的时候，他的bucket数组最多就有32个，而local depth是每个bucket的成员，他指明了找到该bucket需要的位数，例如说 这里我分析的是https://github.com/nitish6174/extendible-hashing/blob/master/main.cpp里面的代码，内容还是比较好懂的接下来首先是他的bucket部分，这个比较简单，就是一些常规的增删查改操作， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116Bucket::Bucket(int depth, int size){ this-&gt;depth = depth; this-&gt;size = size;}int Bucket::insert(int key, string value){ std::map&lt;int,string&gt;::iterator it; it = values.find(key); if(it!=values.end()) return -1; if(isFull()) return 0; values[key] = value; return 1;}int Bucket::remove(int key){ std::map&lt;int,string&gt;::iterator it; it = values.find(key); if(it!=values.end()) { values.erase(it); return 1; } else { cout&lt;&lt;&quot;Cannot remove : This key does not exists&quot;&lt;&lt;endl; return 0; }}int Bucket::update(int key, string value){ std::map&lt;int,string&gt;::iterator it; it = values.find(key); if(it!=values.end()) { values[key] = value; cout&lt;&lt;&quot;Value updated&quot;&lt;&lt;endl; return 1; } else { cout&lt;&lt;&quot;Cannot update : This key does not exists&quot;&lt;&lt;endl; return 0; }}void Bucket::search(int key){ std::map&lt;int,string&gt;::iterator it; it = values.find(key); if(it!=values.end()) { cout&lt;&lt;&quot;Value = &quot;&lt;&lt;it-&gt;second&lt;&lt;endl; } else { cout&lt;&lt;&quot;This key does not exists&quot;&lt;&lt;endl; }}int Bucket::isFull(void){ if(values.size()==size) return 1; else return 0;}int Bucket::isEmpty(void){ if(values.size()==0) return 1; else return 0;}int Bucket::getDepth(void){ return depth;}int Bucket::increaseDepth(void){ depth++; return depth;}int Bucket::decreaseDepth(void){ depth--; return depth;}std::map&lt;int, string&gt; Bucket::copy(void){ std::map&lt;int, string&gt; temp(values.begin(),values.end()); return temp;}void Bucket::clear(void){ values.clear();}void Bucket::display(){ std::map&lt;int,string&gt;::iterator it; for(it=values.begin();it!=values.end();it++) cout&lt;&lt;it-&gt;first&lt;&lt;&quot; &quot;; cout&lt;&lt;endl;} 接下来就是directory的内容，首先是他的构造函数 123456789Directory::Directory(int depth, int bucket_size){ this-&gt;global_depth = depth; this-&gt;bucket_size = bucket_size; for(int i = 0 ; i &lt; 1&lt;&lt;depth ; i++ ) { buckets.push_back(new Bucket(depth,bucket_size)); }} 可以看到，他一开始的local depth和global depth是一样的，其哈希函数如下： 1234int Directory::hash(int n){ return n&amp;((1&lt;&lt;global_depth)-1);} 很直白的，就是取n的二进制位的最后global depth位做为哈希值，例如说当global depth为3时，上面就是n&amp;7（111）了下面是一个取pair的函数 1234int Directory::pairIndex(int bucket_no, int depth){ return bucket_no^(1&lt;&lt;(depth-1));} 这个是在桶进行split的时候调用的，这里在被调用时被分裂的桶的bucket_no+1才等于参数depth，例如说bucket_no是6（110）的时候，depth是4，那么做取异操作后，返回的是14（1110），和原来的6（0110）相比，就是在增加的哈希位上不同了，这里具体为啥这么做见后面的grow就知道了 123456void Directory::grow(void){ for(int i = 0 ; i &lt; 1&lt;&lt;global_depth ; i++ ) buckets.push_back(buckets[i]); global_depth++;} grow函数是在bucket分裂时发现他分裂后的local depth比global depth还大时调用的，调用后bucket数组翻倍，而且他翻倍后多出来的数组元素，比如说原来是n个，现在2n个，第n+1个和第1个指向同1个bucket，因为push_back会生成原来指针的副本，他也指向原来的指针所指对象，所以grow的过程并没有真正的创建bucket对象，只是多出了一些类似占位符的东西。而且看到这里上面的pairindex函数就明白了，pair指的就是这里的指针11对应的关系，bucket数组的第6个和第14个都指向同1个bucket对象，我们取得他的下标，给他赋予真正的新的bucket对象（见下面的split) 12345678910111213141516171819202122void Directory::split(int bucket_no){ int local_depth,pair_index,index_diff,dir_size,i; map&lt;int, string&gt; temp; map&lt;int, string&gt;::iterator it; local_depth = buckets[bucket_no]-&gt;increaseDepth(); if(local_depth&gt;global_depth) grow(); pair_index = pairIndex(bucket_no,local_depth); buckets[pair_index] = new Bucket(local_depth,bucket_size); temp = buckets[bucket_no]-&gt;copy(); buckets[bucket_no]-&gt;clear(); index_diff = 1&lt;&lt;local_depth; dir_size = 1&lt;&lt;global_depth; for( i=pair_index-index_diff ; i&gt;=0 ; i-=index_diff ) buckets[i] = buckets[pair_index]; for( i=pair_index+index_diff ; i&lt;dir_size ; i+=index_diff ) buckets[i] = buckets[pair_index]; for(it=temp.begin();it!=temp.end();it++) insert((*it).first,(*it).second,1);} 首先是调用要分裂的那个bucket的increasedepth函数，他的local depth+1了，如果需要扩容调用grow函数，接着是找到指向同1个bucket的bucket_no(pairindex函数)，然后在他上面真正的创建1个新的bucket，然后把需要分裂的那个桶的内容赋值给temp变量并清空，准备后面的分配，而接下来的操作则是bucket数组里的某几个指向新建立的bucket，这里我们具体以一个例子说明假设一开始global depth和local depth都是3，后来有某个桶7（111）他要split，发现global depth不够，于是需要grow，然后就走上述流程，接着算出index_diff和dir_size都是16，pair_index是15（1111），那么很明显2个for循环都不满足条件不执行，因为除了7和15外就没有哪个bucket_no指向相关的桶了，但假如后来桶7（0111，这个时候是4层了）又不够了，又要扩容了，global depth就变成5了，一切如上照旧；后来桶7又不够用。又分裂了，global depth变为6了，不过这个时候和原来8个桶相比，只多了3个桶而已到了后面，终于是1个local depth是3的桶要分裂了，假设他是6（110），他发现global depth够用，就不用grow了，他的pair_index是14（1110），index_diff是16，dir_size是64，第1个for没走，但第2个，他会遍历30（011110），46（101110），62（111110），这3个桶都指向新分裂出来的桶，原本他们指向的和6一样的桶，至于为啥这么做，我的想法是，当global depth比local depth多到1定程度时，指向同1个桶的哈希下标是有很多的，这个时候就需要新生成的桶来分担一些，例如上面的6，在没分裂前，后3位是110的桶的下标都指向了6,的桶，分裂后，后四位是0110的依旧，但1110的则被分配去新的桶了，假如不这么做的话，到后面可能就出现某些桶需要频繁地分裂的结果接下来就是insert函数，其实现如下 123456789101112131415161718192021void Directory::insert(int key,string value,bool reinserted){ int bucket_no = hash(key); int status = buckets[bucket_no]-&gt;insert(key,value); if(status==1) { if(!reinserted) cout&lt;&lt;&quot;Inserted key &quot;&lt;&lt;key&lt;&lt;&quot; in bucket &quot;&lt;&lt;bucket_id(bucket_no)&lt;&lt;endl; else cout&lt;&lt;&quot;Moved key &quot;&lt;&lt;key&lt;&lt;&quot; to bucket &quot;&lt;&lt;bucket_id(bucket_no)&lt;&lt;endl; } else if(status==0) { split(bucket_no); insert(key,value,reinserted); } else { cout&lt;&lt;&quot;Key &quot;&lt;&lt;key&lt;&lt;&quot; already exists in bucket &quot;&lt;&lt;bucket_id(bucket_no)&lt;&lt;endl; }} 首先是计算哈希值，例如说上面的例子继续下去，此时的global depth是6，这里根据上面的例子，对于后4位是1110的，他们会指向同1个桶，而后4位是0110的，他们会指向另外1个桶，可万一他原本就要溢出的桶里面，每条记录的后4位都是0110呢，这个时候他们就都走到同1个桶了，就又溢出了，这个时候上面代码就根据insert的返回值判断是否溢出，溢出了，则要对bucket_no这个桶再一次split，例如说我们假设的6（0110，现在是4位local depth），6的pair index这个时候是22了（10110），split也顺带把54指向了新生成的桶（110110，接下来就是根据5位二进制去判断了，因为我们原本假设他们后4位都是0110，现在就进一步地根据第5位是0还是1去判断走哪个桶了，如果还溢出，就继续分裂，知道没有溢出为止。总结目前上述内容，就是一种平衡吧，当global depth是6的时候，在6（110）这个下标的桶还没分裂前，有8个哈希下标会指向他，分裂的同时也应该能使得new出来的桶分担一些那接下来有分必有合，shrink操作函数如下 123456789101112131415void Directory::shrink(void){ int i,flag=1; for( i=0 ; i&lt;buckets.size() ; i++ ) { if(buckets[i]-&gt;getDepth()==global_depth) { flag=0; return; } } global_depth--; for(i = 0 ; i &lt; 1&lt;&lt;global_depth ; i++ ) buckets.pop_back();} 如果有1个桶的local depth和global depth一样，就无法缩小了，原因可以看到后面他缩小的操作，实际上就是把后半部分的bucket给去掉了，而能没有后果的去掉的前提是，这些bucket指向的对象完全和前半部分的一样，但假如其中某个桶的local depth和global depth一样，说明是经过了split中的new Bucket(local_depth,bucket_size)操作，导致这后半部分有某个桶他指向了新的对象，也就无法删除了，下面是merge函数 1234567891011121314151617181920void Directory::merge(int bucket_no){ int local_depth,pair_index,index_diff,dir_size,i; local_depth = buckets[bucket_no]-&gt;getDepth(); pair_index = pairIndex(bucket_no,local_depth); index_diff = 1&lt;&lt;local_depth; dir_size = 1&lt;&lt;global_depth; if( buckets[pair_index]-&gt;getDepth() == local_depth ) { buckets[pair_index]-&gt;decreaseDepth(); delete(buckets[bucket_no]); buckets[bucket_no] = buckets[pair_index]; for( i=bucket_no-index_diff ; i&gt;=0 ; i-=index_diff ) buckets[i] = buckets[pair_index]; for( i=bucket_no+index_diff ; i&lt;dir_size ; i+=index_diff ) buckets[i] = buckets[pair_index]; }} 这里就是split反过来，例如说上面的例子，我想merge22，他的pair index是6，且他们的local depth都是5，这个时候就可以走if里面的流程，把这个local depth减1，然后删去22这个桶，且让6所指的桶的指针给了22，然后就是把那些原来指向22的桶现在指向6，就是和上面split一样的思路下面是remove函数 123456789101112131415void Directory::remove(int key,int mode){ int bucket_no = hash(key); if(buckets[bucket_no]-&gt;remove(key)) cout&lt;&lt;&quot;Deleted key &quot;&lt;&lt;key&lt;&lt;&quot; from bucket &quot;&lt;&lt;bucket_id(bucket_no)&lt;&lt;endl; if(mode&gt;0) { if(buckets[bucket_no]-&gt;isEmpty() &amp;&amp; buckets[bucket_no]-&gt;getDepth()&gt;1) merge(bucket_no); } if(mode&gt;1) { shrink(); }} mode是用户输入的，根据他来判断是要merge（删去某个桶）还是直接对半砍去剩下的几个没列出来的也只是很简单的操作，这个代码也就分析完咯，下面就开始做project2捏","link":"/2022/09/07/%E4%B8%80%E4%B8%AA%E5%8F%AF%E6%89%A9%E5%B1%95%E5%93%88%E5%B8%8C%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/"},{"title":"引用折叠","text":"所谓的万能引用主要是用在以下2种场合：第1种是模板如下： 12template&lt;typename T&gt;void func(T&amp;&amp; t){...} 以上代码中的&amp;&amp;并不是右值引用的意思，他是表示说这个t肯定是一个引用类型，但具体是左值引用还是右值引用我们得根据传进来的参数确定那如何根据传进来的参数确定呢，这里就用到了引用折叠了，具体而言，当T被推导出来是右值时，T&amp;&amp;是一个右值引用（&amp;&amp; &amp;&amp; 折叠为了&amp;&amp;），而其他情况都是折叠为&amp;，即左值引用为了验证，我们可以用完美转发来验证一下 12345678910111213141516171819202122#include &lt;iostream&gt;void print(int&amp; t){ std::cout &lt;&lt; &quot;left&quot; &lt;&lt; std::endl;}void print(int&amp;&amp; t){ std::cout &lt;&lt; &quot;right&quot; &lt;&lt; std::endl;}template&lt;typename T&gt;void func(T&amp;&amp; t){ print(std::forward&lt;T&gt;(t));}int main(){ int x = 10; func(x); func(12); func(std::move(x)); int&amp; y = x; func(y);} 以上代码第1个显示是left，x是一个左值为什么被推导为左值引用呢，因为在func的参数里，传进来的T&amp;&amp;必须被解释为1个引用，那T就可以是int，int&amp;，int&amp;&amp;，只有int&amp;能被推断为左值(int&amp; &amp;&amp;折叠为&amp;)，第2个则是right，T是实例化为int，第3个为right，T为int&amp;&amp;，第4个T为int&amp;，折叠为&amp;，所以结果是left 第2种使用万能引用的场合是在auto推断中，如 12auto&amp;&amp; i = 3； //auto推断为int，i为int&amp;&amp;类型，即右值引用auto&amp;&amp; j = i; // auto推断为int&amp;，i为int&amp;，即左值引用","link":"/2022/09/07/%E5%BC%95%E7%94%A8%E6%8A%98%E5%8F%A0/"}],"tags":[{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"c+2","slug":"c-2","link":"/tags/c-2/"},{"name":"tvm","slug":"tvm","link":"/tags/tvm/"},{"name":"小组件","slug":"小组件","link":"/tags/%E5%B0%8F%E7%BB%84%E4%BB%B6/"}],"categories":[]}