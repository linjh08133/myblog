---
title: 一个可扩展哈希代码阅读
date: 2022-09-07 19:36:00
tags: 小组件
---

可扩展哈希一般是用在数据库中管理1条1条的record的，虽然现在很多都是用B+树了
这个主要是做15-445的project时接触到的，project2需要实现1个可扩展哈希
静态的哈希随着记录的增多，其冲突的概率也越来越大，此时如果能动态扩容就能优化性能了
可扩展哈希的主要成员就2个，一个是bucket，它内部存放的就是1条1条的记录，一般初始化的时候就指定他的可存放记录的数目，多个bucket就构成了整个hash表
第2个是directory，他是1个可以扩展的数组，每个成员都是指针，指向对应的bucket，其对应的bucket就是通过哈希函数算出对应的下标，且可能会有多个成员指向同个bucket的情况，这个后面再说
还有的就是2个重要的概念：global depth和local depth，前者是directory的成员，它指明了每个bucket最大的local depth，也限制了其管理的bucket指针数组的大小，例如说global depth是5的时候，他的bucket数组最多就有32个，而local depth是每个bucket的成员，他指明了找到该bucket需要的位数，例如说

这里我分析的是https://github.com/nitish6174/extendible-hashing/blob/master/main.cpp
里面的代码，内容还是比较好懂的
接下来首先是他的bucket部分，这个比较简单，就是一些常规的增删查改操作，

~~~
Bucket::Bucket(int depth, int size)
{
    this->depth = depth;
    this->size = size;
}

int Bucket::insert(int key, string value)
{
    std::map<int,string>::iterator it;
    it = values.find(key);
    if(it!=values.end())
        return -1;
    if(isFull())
        return 0;
    values[key] = value;
    return 1;
}

int Bucket::remove(int key)
{
    std::map<int,string>::iterator it;
    it = values.find(key);
    if(it!=values.end())
    {
        values.erase(it);
        return 1;
    }
    else
    {
        cout<<"Cannot remove : This key does not exists"<<endl;
        return 0;
    }
}

int Bucket::update(int key, string value)
{
    std::map<int,string>::iterator it;
    it = values.find(key);
    if(it!=values.end())
    {
        values[key] = value;
        cout<<"Value updated"<<endl;
        return 1;
    }
    else
    {
        cout<<"Cannot update : This key does not exists"<<endl;
        return 0;
    }
}

void Bucket::search(int key)
{
    std::map<int,string>::iterator it;
    it = values.find(key);
    if(it!=values.end())
    {
        cout<<"Value = "<<it->second<<endl;
    }
    else
    {
        cout<<"This key does not exists"<<endl;
    }
}

int Bucket::isFull(void)
{
    if(values.size()==size)
        return 1;
    else
        return 0;
}

int Bucket::isEmpty(void)
{
    if(values.size()==0)
        return 1;
    else
        return 0;
}

int Bucket::getDepth(void)
{
    return depth;
}

int Bucket::increaseDepth(void)
{
    depth++;
    return depth;
}

int Bucket::decreaseDepth(void)
{
    depth--;
    return depth;
}

std::map<int, string> Bucket::copy(void)
{
    std::map<int, string> temp(values.begin(),values.end());
    return temp;
}

void Bucket::clear(void)
{
    values.clear();
}

void Bucket::display()
{
    std::map<int,string>::iterator it;
    for(it=values.begin();it!=values.end();it++)
        cout<<it->first<<" ";
    cout<<endl;
}
~~~

接下来就是directory的内容，首先是他的构造函数
~~~
Directory::Directory(int depth, int bucket_size)
{
    this->global_depth = depth;
    this->bucket_size = bucket_size;
    for(int i = 0 ; i < 1<<depth ; i++ )
    {
        buckets.push_back(new Bucket(depth,bucket_size));
    }
}
~~~
可以看到，他一开始的local depth和global depth是一样的，其哈希函数如下：
~~~
int Directory::hash(int n)
{
    return n&((1<<global_depth)-1);
}
~~~
很直白的，就是取n的二进制位的最后global depth位做为哈希值，例如说当global depth为3时，上面就是n&7（111）了
下面是一个取pair的函数
~~~
int Directory::pairIndex(int bucket_no, int depth)
{
    return bucket_no^(1<<(depth-1));
}
~~~
这个是在桶进行split的时候调用的，这里在被调用时被分裂的桶的bucket_no+1才等于参数depth，例如说bucket_no是6（110）的时候，depth是4，那么做取异操作后，返回的是14（1110），和原来的6（0110）相比，就是在增加的哈希位上不同了，这里具体为啥这么做见后面的grow就知道了
~~~
void Directory::grow(void)
{
    for(int i = 0 ; i < 1<<global_depth ; i++ )
        buckets.push_back(buckets[i]);
    global_depth++;
}
~~~
grow函数是在bucket分裂时发现他分裂后的local depth比global depth还大时调用的，调用后bucket数组翻倍，而且他翻倍后多出来的数组元素，比如说原来是n个，现在2n个，第n+1个和第1个指向同1个bucket，因为push_back会生成原来指针的副本，他也指向原来的指针所指对象，所以grow的过程并没有真正的创建bucket对象，只是多出了一些类似占位符的东西。而且看到这里上面的pairindex函数就明白了，pair指的就是这里的指针11对应的关系，bucket数组的第6个和第14个都指向同1个bucket对象，我们取得他的下标，给他赋予真正的新的bucket对象（见下面的split)
~~~
void Directory::split(int bucket_no)
{
    int local_depth,pair_index,index_diff,dir_size,i;
    map<int, string> temp;
    map<int, string>::iterator it;

    local_depth = buckets[bucket_no]->increaseDepth();
    if(local_depth>global_depth)
        grow();
    pair_index = pairIndex(bucket_no,local_depth);
    buckets[pair_index] = new Bucket(local_depth,bucket_size);
    temp = buckets[bucket_no]->copy();
    buckets[bucket_no]->clear();
    index_diff = 1<<local_depth;
    dir_size = 1<<global_depth;
    for( i=pair_index-index_diff ; i>=0 ; i-=index_diff )
        buckets[i] = buckets[pair_index];
    for( i=pair_index+index_diff ; i<dir_size ; i+=index_diff )
        buckets[i] = buckets[pair_index];
    for(it=temp.begin();it!=temp.end();it++)
        insert((*it).first,(*it).second,1);
}
~~~
首先是调用要分裂的那个bucket的increasedepth函数，他的local depth+1了，如果需要扩容调用grow函数，接着是找到指向同1个bucket的bucket_no(pairindex函数)，然后在他上面真正的创建1个新的bucket，然后把需要分裂的那个桶的内容赋值给temp变量并清空，准备后面的分配，而接下来的操作则是bucket数组里的某几个指向新建立的bucket，这里我们具体以一个例子说明
假设一开始global depth和local depth都是3，后来有某个桶7（111）他要split，发现global depth不够，于是需要grow，然后就走上述流程，接着算出index_diff和dir_size都是16，pair_index是15（1111），那么很明显2个for循环都不满足条件不执行，因为除了7和15外就没有哪个bucket_no指向相关的桶了，但假如后来桶7（0111，这个时候是4层了）又不够了，又要扩容了，global depth就变成5了，一切如上照旧；后来桶7又不够用。又分裂了，global depth变为6了，不过这个时候和原来8个桶相比，只多了3个桶而已
到了后面，终于是1个local depth是3的桶要分裂了，假设他是6（110），他发现global depth够用，就不用grow了，他的pair_index是14（1110），index_diff是16，dir_size是64，第1个for没走，但第2个，他会遍历30（011110），46（101110），62（111110），这3个桶都指向新分裂出来的桶，原本他们指向的和6一样的桶，至于为啥这么做，我的想法是，当global depth比local depth多到1定程度时，指向同1个桶的哈希下标是有很多的，这个时候就需要新生成的桶来分担一些，例如上面的6，在没分裂前，后3位是110的桶的下标都指向了6,的桶，分裂后，后四位是0110的依旧，但1110的则被分配去新的桶了，假如不这么做的话，到后面可能就出现某些桶需要频繁地分裂的结果
接下来就是insert函数，其实现如下
~~~
void Directory::insert(int key,string value,bool reinserted)
{
    int bucket_no = hash(key);
    int status = buckets[bucket_no]->insert(key,value);
    if(status==1)
    {
        if(!reinserted)
            cout<<"Inserted key "<<key<<" in bucket "<<bucket_id(bucket_no)<<endl;
        else
            cout<<"Moved key "<<key<<" to bucket "<<bucket_id(bucket_no)<<endl;
    }
    else if(status==0)
    {
        split(bucket_no);
        insert(key,value,reinserted);
    }
    else
    {
        cout<<"Key "<<key<<" already exists in bucket "<<bucket_id(bucket_no)<<endl;
    }
}
~~~
首先是计算哈希值，例如说上面的例子继续下去，此时的global depth是6，这里根据上面的例子，对于后4位是1110的，他们会指向同1个桶，而后4位是0110的，他们会指向另外1个桶，可万一他原本就要溢出的桶里面，每条记录的后4位都是0110呢，这个时候他们就都走到同1个桶了，就又溢出了，这个时候上面代码就根据insert的返回值判断是否溢出，溢出了，则要对bucket_no这个桶再一次split，例如说我们假设的6（0110，现在是4位local depth），6的pair index这个时候是22了（10110），split也顺带把54指向了新生成的桶（110110，接下来就是根据5位二进制去判断了，因为我们原本假设他们后4位都是0110，现在就进一步地根据第5位是0还是1去判断走哪个桶了，如果还溢出，就继续分裂，知道没有溢出为止。
总结目前上述内容，就是一种平衡吧，当global depth是6的时候，在6（110）这个下标的桶还没分裂前，有8个哈希下标会指向他，分裂的同时也应该能使得new出来的桶分担一些
那接下来有分必有合，shrink操作函数如下
~~~
void Directory::shrink(void)
{
    int i,flag=1;
    for( i=0 ; i<buckets.size() ; i++ )
    {
        if(buckets[i]->getDepth()==global_depth)
        {
            flag=0;
            return;
        }
    }
    global_depth--;
    for(i = 0 ; i < 1<<global_depth ; i++ )
        buckets.pop_back();
}
~~~
如果有1个桶的local depth和global depth一样，就无法缩小了，原因可以看到后面他缩小的操作，实际上就是把后半部分的bucket给去掉了，而能没有后果的去掉的前提是，这些bucket指向的对象完全和前半部分的一样，但假如其中某个桶的local depth和global depth一样，说明是经过了split中的new Bucket(local_depth,bucket_size)操作，导致这后半部分有某个桶他指向了新的对象，也就无法删除了，
下面是merge函数
~~~
void Directory::merge(int bucket_no)
{
    int local_depth,pair_index,index_diff,dir_size,i;

    local_depth = buckets[bucket_no]->getDepth();
    pair_index = pairIndex(bucket_no,local_depth);
    index_diff = 1<<local_depth;
    dir_size = 1<<global_depth;

    if( buckets[pair_index]->getDepth() == local_depth )
    {
        buckets[pair_index]->decreaseDepth();
        delete(buckets[bucket_no]);
        buckets[bucket_no] = buckets[pair_index];
        for( i=bucket_no-index_diff ; i>=0 ; i-=index_diff )
            buckets[i] = buckets[pair_index];
        for( i=bucket_no+index_diff ; i<dir_size ; i+=index_diff )
            buckets[i] = buckets[pair_index];
    }
}
~~~
这里就是split反过来，例如说上面的例子，我想merge22，他的pair index是6，且他们的local depth都是5，这个时候就可以走if里面的流程，把这个local depth减1，然后删去22这个桶，且让6所指的桶的指针给了22，然后就是把那些原来指向22的桶现在指向6，就是和上面split一样的思路
下面是remove函数
~~~
void Directory::remove(int key,int mode)
{
    int bucket_no = hash(key);
    if(buckets[bucket_no]->remove(key))
        cout<<"Deleted key "<<key<<" from bucket "<<bucket_id(bucket_no)<<endl;
    if(mode>0)
    {
        if(buckets[bucket_no]->isEmpty() && buckets[bucket_no]->getDepth()>1)
            merge(bucket_no);
    }
    if(mode>1)
    {
        shrink();
    }
}
~~~
mode是用户输入的，根据他来判断是要merge（删去某个桶）还是直接对半砍去
剩下的几个没列出来的也只是很简单的操作，这个代码也就分析完咯，下面就开始做project2捏
